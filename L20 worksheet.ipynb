{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset loader\n",
    "from sklearn import datasets\n",
    "\n",
    "# model training and evalutation utilities \n",
    "from sklearn.model_selection import train_test_split # very important!\n",
    "from sklearn.model_selection import cross_validate   # v nice!\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold # this is one way to generate folds\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# toy data\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you should learn/be aware of based on this lecture \n",
    "\n",
    "Key `sklearn` functions:\n",
    "- `train_test_split`\n",
    "- `cross_validate`\n",
    "- Fold generators: `KFold` and `StratifiedKFold`\n",
    "- Scoring functions per last lecture and how to pass to `cross_validate`\n",
    "- How to compare different models by looping over them with `cross_validate`, `GridSearchCV`, or `RandomizedSearchCV` \n",
    "\n",
    "Not covered today but you should check out:\n",
    "- `confusion_matrix` and `classification_report` (helpful to evaluate models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple \"split, train, evaluate\" example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "# ignore the model I choose here, its not important what\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(X1, y1) # fit on the \"training data\" X1 and  y1\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(y2, y2_model) # see how close y2 is to prediction (fraction of all pred that are exactly right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to do k-fold? It's like repeating the above. In pseudo code, it looks like:\n",
    "1. Break the X and y data into $k$ subsamples\n",
    "2. For each subsample, fit the model, predict OOS, score predictions, and save those\n",
    "\n",
    "Ok?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold in Python: The explicit way, and the wrapped way\n",
    "\n",
    "Watch me do the explicit way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9666666666666667,\n",
       " 0.9666666666666667,\n",
       " 0.9333333333333333,\n",
       " 0.9333333333333333,\n",
       " 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can take quick notes here, but I'm not going to write this code slow enough to copy\n",
    "# the point here is to illustrate\n",
    "\n",
    "accuracy = [] # to store accuracies\n",
    "\n",
    "# loop over folds \n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X,y):\n",
    "\n",
    "    # .split() yields the indices in train/test sets. use those to get \n",
    "    # the x/y vars for each separated out:\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # fit/estimate, predict OOS, evaluate and store\n",
    "    model.fit(X_train,y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    accuracy.append(   accuracy_score(y_test, y_predict)      )\n",
    "    \n",
    "accuracy # print   \n",
    "# import numpy as np\n",
    "# np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the wrapper below! We are going to see how to use that function to:\n",
    "- try multiple models\n",
    "- try different sets of X variables\n",
    "- try different ways to specific folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.        , 0.00099707, 0.00098538, 0.        , 0.00099969]),\n",
       " 'score_time': array([0.0029757 , 0.00051785, 0.00099826, 0.00199819, 0.00199223]),\n",
       " 'test_score': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the function here\n",
    "cross_validate(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.        , 0.        , 0.0009973 , 0.        , 0.00099659]),\n",
       " 'score_time': array([0.00299144, 0.00299263, 0.00199223, 0.00299287, 0.00199533]),\n",
       " 'test_accuracy': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ]),\n",
       " 'test_r2': array([0.95, 0.95, 0.9 , 0.9 , 1.  ]),\n",
       " 'test_precision_macro': array([0.96969697, 0.96969697, 0.94444444, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try here with diff scores\n",
    "\n",
    "cross_validate(model, X, y, scoring=['accuracy','r2','precision_macro'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the metrics it can compute out of the box are here: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "Notice that many of these were discussed in our last lecture!\n",
    "\n",
    "_**Warning/Note:**_ the metric names on that link and what you put in the `scoring` dictionary don't seem to match up.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question:\n",
    "\n",
    "Using 5 folds, what is the average (across the folds) out-of-sample (training) F1?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9598319029897976"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model,X,y,scoring='f1_macro') ['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the `cross_validate` parameters\n",
    "\n",
    "### The model parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0009973 , 0.00099897, 0.0009954 , 0.00099754, 0.        ]),\n",
       " 'score_time': array([0.0009985 , 0.00099659, 0.0009985 , 0.        , 0.00099707]),\n",
       " 'test_score': array([0.96658312, 1.        , 1.        , 0.96658312, 1.        ])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the model\n",
    "\n",
    "# yb changing the model parameter, you can adj the tyupe of model and the models parameters\n",
    "cross_validate( SVC(gamma='auto'),X,y,scoring='f1_macro')\n",
    "cross_validate( SVC(C=5),X,y,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question:\n",
    "\n",
    "try to use a regression model, (you can't use f1 on this, so evaluate on r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3225607248900085"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer here\n",
    "cross_validate( LinearRegression() ,X,y,scoring='r2') ['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear_model` submodule contains lots of useful alternate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.\n",
    "\n",
    "# for example:\n",
    "linear_model.Lasso\n",
    "linear_model.Ridge\n",
    "linear_model.LogisticRegression\n",
    "\n",
    "linear_model.LassoCV() # Returns a Lasso (L1 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.RidgeCV() # Returns a Ridge (L2 Regularization) linear model with picking the best model by cross validation\n",
    "linear_model.LogisticRegressionCV() # return best logit model by CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up models to try\n",
    "models = []\n",
    "models.append(('svc_1', SVC(gamma='auto') ))\n",
    "models.append(('svc_2', SVC(C=5) ))\n",
    "models.append(('neighbor1',  KNeighborsClassifier(n_neighbors=1)))\n",
    "models[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_1     : 0.980 (0.016)\n",
      "svc_2     : 0.987 (0.016)\n",
      "neighbor1 : 0.960 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# loop and print\n",
    "for name, model in models:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy', cv=5)\n",
    "    print('%s: %.3f (%.3f)' % (name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biult in methods \n",
    "\n",
    "gridsearchCV\n",
    "\n",
    "randomizedsearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The X parameter\n",
    "\n",
    "You can loop over Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a smaller X and a bigger X\n",
    "X_small = X[:,:2] # just first two columns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X3 = poly.fit_transform(X) # has not 4 vars, but 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X         : 0.960 (0.025)\n",
      "X_small   : 0.727 (0.061)\n",
      "X3        : 0.947 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# set up Xs to try\n",
    "Xs = []\n",
    "Xs.append( ('X' ,X ))\n",
    "Xs.append( ('X_small' ,X_small   ))\n",
    "Xs.append( ('X3'   ,X3     ))\n",
    "\n",
    "# loop and print\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "for X_name, X in Xs:\n",
    "    scores = cross_validate(model, X, y, scoring='accuracy', cv=5)\n",
    "    print('%s: %.3f (%.3f)' % (X_name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xs and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_1      + X         : 0.980 (0.016)\n",
      "svc_2      + X         : 0.987 (0.016)\n",
      "neighbor1  + X         : 0.960 (0.025)\n",
      "svc_1      + X_small   : 0.820 (0.058)\n",
      "svc_2      + X_small   : 0.813 (0.054)\n",
      "neighbor1  + X_small   : 0.727 (0.061)\n",
      "svc_1      + X3        : 0.527 (0.077)\n",
      "svc_2      + X3        : 0.973 (0.025)\n",
      "neighbor1  + X3        : 0.947 (0.016)\n"
     ]
    }
   ],
   "source": [
    "# i willl post this!\n",
    "\n",
    "for X_name, X in Xs:\n",
    "    for name, model in models: \n",
    "        scores = cross_validate(model, X, y, scoring='accuracy', cv=5)\n",
    "        print('%s + %s: %.3f (%.3f)' % (name.ljust(10),\n",
    "                                        X_name.ljust(10), \n",
    "                                       scores['test_score'].mean(), \n",
    "                                       scores['test_score'].std()\n",
    "                                       )\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV parameter and folds\n",
    "\n",
    "Just  watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00101757, 0.00099778, 0.00099778, 0.0009954 , 0.        ]),\n",
       " 'score_time': array([0.00297141, 0.00199604, 0.0019958 , 0.00099826, 0.00098968]),\n",
       " 'test_score': array([0.93333333, 0.96666667, 0.93333333, 0.93333333, 0.96666667])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(model, X, y, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silly data for illustration\n",
    "y= [\"a\",'a','a','b','b','b','c','c','c']\n",
    "\n",
    "# a/b/c are equal % of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0 1 3 4 5 7]                    test: [2 6 8]\n",
      "       ['a', 'a', 'b', 'b', 'b', 'c']         ['a', 'c', 'c']\n",
      "\n",
      "train: [2 3 4 5 6 8]                    test: [0 1 7]\n",
      "       ['a', 'b', 'b', 'b', 'c', 'c']         ['a', 'a', 'c']\n",
      "\n",
      "train: [0 1 2 6 7 8]                    test: [3 4 5]\n",
      "       ['a', 'a', 'a', 'c', 'c', 'c']         ['b', 'b', 'b']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)    \n",
    "kf = KFold(n_splits=3,shuffle=True,random_state=1)   # must give state!  \n",
    "\n",
    "for train, test in kf.split(y):       # for each fold,\n",
    "    print(\"train: %s test: %s\" % (str(train).ljust(32), test))   # but here, just show \n",
    "    print(\"       %s       %s\" % (str([y[j] for j in train]).ljust(32), [y[j] for j in test]))\n",
    "    print() #blank line\n",
    "    \n",
    "# kfold --> splits it BY INDEX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1 2 4 5 7 8]                    test: [0 3 6]\n",
      "       ['a', 'a', 'b', 'b', 'c', 'c']         ['a', 'b', 'c']\n",
      "\n",
      "train: [0 2 3 5 6 8]                    test: [1 4 7]\n",
      "       ['a', 'a', 'b', 'b', 'c', 'c']         ['a', 'b', 'c']\n",
      "\n",
      "train: [0 1 3 4 6 7]                    test: [2 5 8]\n",
      "       ['a', 'a', 'b', 'b', 'c', 'c']         ['a', 'b', 'c']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "# skf = StratifiedKFold(n_splits=3,shuffle=True,random_state=1) # now random\n",
    "X = y # skf needs an X and y variable\n",
    "for train, test in skf.split(X,y):       # for each fold,\n",
    "    print(\"train: %s test: %s\" % (str(train).ljust(32), test))   # but here, just show \n",
    "    print(\"       %s       %s\" % (str([y[j] for j in train]).ljust(32), [y[j] for j in test]))\n",
    "    print() #blank line\n",
    "\n",
    "# skf keeps fractions of a/b/c as equal as possible in test/train to overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kf        : 0.000 (0.000)\n",
      "kf_rand   : 0.947 (0.025)\n",
      "skf_3     : 0.960 (0.016)\n",
      "skf_3_rand: 0.953 (0.009)\n",
      "skf_5     : 0.960 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# reload the X and y variables (we jsut overwrote)\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "cross_validate(model, X, y, cv=StratifiedKFold(n_splits=3)  , scoring='accuracy')\n",
    "\n",
    "# set up folds to try\n",
    "folds = []\n",
    "folds.append(('kf', KFold(n_splits=3)   ))\n",
    "folds.append(('kf_rand', KFold(n_splits=3,shuffle=True,random_state=1)  ))\n",
    "folds.append(('skf_3',       StratifiedKFold(n_splits=3)))\n",
    "folds.append(('skf_3_rand',  StratifiedKFold(n_splits=3,shuffle=True,random_state=1)))\n",
    "folds.append(('skf_5',       StratifiedKFold(n_splits=5)))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "# loop and print\n",
    "for fold_name, fold in folds:\n",
    "    scores = cross_validate(model, X, y, cv=fold, scoring='accuracy')\n",
    "    print('%s: %.3f (%.3f)' % (fold_name.ljust(10), \n",
    "                                   scores['test_score'].mean(), \n",
    "                                   scores['test_score'].std()\n",
    "                                   )\n",
    "         )\n",
    "\n",
    "# lol the kf completely failed... probably had new types OOS    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links, resoruces, and next week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two resources needed\n",
    "- sklearn docs are GREAT https://scikit-learn.org/stable/user_guide.html \n",
    "- Python Data Science Handbook (note some module calls are obsolete, so you might need to update code) https://jakevdp.github.io/PythonDataScienceHandbook/index.html\n",
    "\n",
    "Next week:\n",
    "- preprocessing\n",
    "- data transformations\n",
    "- feasture selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
