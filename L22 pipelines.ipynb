{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data is messy. You often need to\n",
    "\n",
    "    Fill in missing values, and possibly create indicator variables so you can track each \"fill\" you made\n",
    "    Encode categorical values\n",
    "    Standardize / feature scaling\n",
    "\n",
    "And when you have many variables of many types in a dataset, this process can get especially ugly!\n",
    "\n",
    "And for all its strengths, `sklearn+numpy` just doesn't match pandas for work-ability or viewing.\n",
    "\n",
    "So here is the code we'd need to run to finish the exercise last class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DonsLaptop\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.32</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>134007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.81</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.52</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>12.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132396.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.81</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>134481.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.14</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>12.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24322.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.87</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>67366.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.94</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24322.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.54</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.71</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>135038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  mean  std   min   25%   50%   75%    max\n",
       "0   135038.0  -0.0  1.0 -1.74 -0.87  0.00  0.87   1.73\n",
       "1   135038.0  -0.0  1.0 -2.32 -0.77  0.01  0.69   4.47\n",
       "2   135038.0   0.0  1.0 -1.66 -0.74 -0.23  0.53   9.02\n",
       "3   135038.0   0.0  1.0 -3.00 -0.81  0.64  0.64   0.64\n",
       "4   135038.0  -0.0  1.0 -3.78 -0.57  0.28  0.57   1.54\n",
       "5   134007.0   0.0  1.0 -3.81 -0.56  0.24  0.52   4.05\n",
       "6   135007.0   0.0  1.0 -1.16 -1.16  0.81  0.81  12.61\n",
       "7   132396.0   0.0  1.0 -2.81 -0.72 -0.03  0.76   2.67\n",
       "8   134481.0   0.0  1.0 -7.14 -0.66  0.24  0.82   2.01\n",
       "9   135038.0   0.0  1.0 -0.14 -0.14 -0.14 -0.14  12.13\n",
       "10  135038.0   0.0  1.0 -1.78 -0.82  0.01  0.97   1.48\n",
       "11   24322.0  -0.0  1.0 -2.48 -0.81  0.17  0.87   3.67\n",
       "12   67366.0  -0.0  1.0 -6.94 -0.60  0.27  0.79   1.95\n",
       "13   24322.0  -0.0  1.0 -0.30 -0.30 -0.30 -0.30   6.99\n",
       "14  135038.0  -0.0  1.0 -1.42 -0.76 -0.28  0.81   2.32\n",
       "15  135038.0  -0.0  1.0 -1.76 -1.01  0.17  0.95   1.73\n",
       "16  135038.0   0.0  1.0 -4.54 -0.51  0.05  0.61   2.34\n",
       "17  135038.0  -0.0  1.0 -1.64 -0.96  0.16  0.72   2.64\n",
       "18  135038.0   0.0  1.0 -1.59 -0.92 -0.27  0.92   2.79\n",
       "19  135038.0   0.0  1.0 -1.65 -0.76 -0.47  0.90   2.42\n",
       "20  135038.0   0.0  1.0 -1.90 -0.63  0.06  0.78   2.29\n",
       "21  135038.0   0.0  1.0 -2.71 -0.38  0.10  0.62   2.81\n",
       "22  135038.0   0.0  1.0 -1.18 -0.99  0.02  0.86   1.88\n",
       "23  135038.0  -0.0  1.0 -2.24 -0.75 -0.12  0.86   2.18\n",
       "24  135038.0   0.0  1.0 -1.60 -0.89 -0.15  0.59   2.31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "import pandas as pd\n",
    "url = 'https://github.com/LeDataSciFi/lectures-spr2020/blob/master/assignment_data/Fannie_Mae_Plus_Data.gzip?raw=true'\n",
    "fannie_mae = pd.read_csv(url,compression='gzip') \n",
    "\n",
    "# one line: standardize all numeric vars \n",
    "# WARNING: THIS IS BAD - not all number vars are continuous\n",
    "# (just illustrating the scale function)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "fannie_array = preprocessing.scale(fannie_mae.select_dtypes('number')) # make sure those variables should be std'zed!\n",
    "\n",
    "# and verify the dataset is normalized\n",
    "pd.DataFrame(fannie_array).describe().T.round(2) \n",
    "\n",
    "# remaining issues you should fix in assignment...\n",
    "# - only do this to true continuous variables\n",
    "# - only keep variables of interest\n",
    "# - impute missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_Identifier', 'Origination_Channel', 'Seller_Name',\n",
       "       'Original_Interest_Rate', 'Original_UPB', 'Original_Loan_Term',\n",
       "       'Original_LTV_(OLTV)', 'Original_Combined_LTV_(CLTV)',\n",
       "       'Number_of_Borrowers', 'Original_Debt_to_Income_Ratio',\n",
       "       'Borrower_Credit_Score_at_Origination', 'Loan_purpose', 'Property_type',\n",
       "       'Number_of_units', 'Occupancy_type', 'Property_state', 'Zip_code_short',\n",
       "       'Primary_mortgage_insurance_percent', 'Product_type',\n",
       "       'Co-borrower_credit_score_at_origination', 'Mortgage_Insurance_type',\n",
       "       'Origination_Date', 'First_payment_date',\n",
       "       'First_time_home_buyer_indicator', 'UNRATE', 'CPIAUCSL', 'Qdate',\n",
       "       'rGDP', 'TCMR', 'POILWTIUSDM', 'TTLCONS', 'DEXUSEU', 'BOPGSTB',\n",
       "       'GOLDAMGBD228NLBM', 'CSUSHPISA', 'MSPUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fannie_mae.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cardinal sin of data leakage CHEATING\n",
    "\n",
    "**Having data in the training sample that you wouldn't have for real world predictions**\n",
    "\n",
    "Examples\n",
    "1. y is explicitly in X (yikes)\n",
    "2. y is a 2018 variable, but there is a 2019 variable in X\n",
    "3. subtle: y is loan default, but X contains employee ID and some employees are brought in to handle trouble-loans (if you include it, the firm can't use the model to deploy the trouble-loan specialists)\n",
    "4. if out-of-sample predicted stock movements have R2 above 10%... unlikely! (or: you'll be richer than Bezos soon)\n",
    "5. this code below\n",
    "\n",
    "```python\n",
    "import #a bunch of sklearn stuff\n",
    "X, y = #load data\n",
    "X = transform(X) # imputation, encode cat vars, standardize\n",
    "\n",
    "# and then you either do these lines:\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=9,train_size=.8)\n",
    "model = # something\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_predict = model.predict(Xtest) # using X2 (out-of-sample data), predict y2\n",
    "accuracy_score(ytest, y_predict)\n",
    "\n",
    "# or this:\n",
    "cross_validate(model,X,y)\n",
    "```\n",
    "\n",
    "\n",
    "**Q: What's the problem here?**\n",
    "\n",
    "**A: `transform(X)` used the whole dataset, so the X_training data was altered using info from X_test**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solving the 5 data leakage examples:\n",
    "\n",
    "- Preventing 1-3,4: Be very familiar with the data and how it was collected and built \n",
    "- Preventing 4,5: Do your data prep _**within**_ CV folds and where the transformations are done using only info from the training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x    sample\n",
    "1    training \n",
    "1    training\n",
    "2    test\n",
    "1    test\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# loop over folds \n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X,y):\n",
    "\n",
    "    # .split() yields the indices in train/test sets. use those to get \n",
    "    # the x/y vars for each separated out:\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    ###################################################################\n",
    "    # NEW: do the data prep inside this fold, only using training data \n",
    "    ###################################################################\n",
    "    \n",
    "    # e.g. figure out means/std in Xtrain so we can impute/std\n",
    "    prep_methods.fit(Xtrain)   # \"fit\" the transform means \"estimate (like in training a model) what to do\"\n",
    "    Xtrain2 = prep_methods.transform(Xtrain)  # apply those to Xtrain to impute and std\n",
    "    \n",
    "    # fit/estimate, predict OOS, evaluate and store\n",
    "    \n",
    "    model.fit(X_train2,y_train)\n",
    "    \n",
    "    ###################################################################\n",
    "    # NEW: transform the test data the same... \n",
    "    ###################################################################\n",
    "    \n",
    "    X_test2 = prep_methods.transform(X_test)  # apply TEST data the FIT from the TRAIN data \n",
    "   \n",
    "    y_predict = model.predict(X_test2)\n",
    "    accuracy.append(   accuracy_score(y_test, y_predict)      )\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines, and our first!\n",
    "\n",
    "Pipelines combine any number of steps in a row, as long as they have a fit, and a transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00101376, 0.0009973 , 0.00097799, 0.00098038, 0.00103855]),\n",
       " 'score_time': array([0.        , 0.00101566, 0.00101399, 0.        , 0.        ]),\n",
       " 'test_score': array([0.96666667, 0.96666667, 0.96666667, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "\n",
    "iris = load_iris() # data\n",
    "\n",
    "# set up the pipeline, which will, given a set of observations \n",
    "# 1. fit and apply these steps to the training fold\n",
    "# 2. in the testing fold, apply the transform and model to predict (no estimation)\n",
    "\n",
    "classifier_pipeline = make_pipeline(\n",
    "                                    preprocessing.StandardScaler(),  # clean the data\n",
    "                                    svm.SVC(C=1)                     # model\n",
    "                                    )\n",
    "\n",
    "# ok go!\n",
    "cross_validate(classifier_pipeline, iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00200057, 0.00197363, 0.00099921, 0.00099683, 0.00099611]),\n",
       " 'score_time': array([0.00298595, 0.00299191, 0.00199318, 0.0009985 , 0.00199485]),\n",
       " 'test_score': array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 1: try this with a Nearest Neighbors Classifier (5 min)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_pipe = make_pipeline(\n",
    "                        preprocessing.StandardScaler(),  # clean the data\n",
    "                        KNeighborsClassifier()           # model\n",
    "                        )\n",
    "\n",
    "# ok go!\n",
    "cross_validate(knn_pipe, iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 2: load this altered dataset and add a step to impute the missing values with the column mean\n",
    "\n",
    "iris2 = load_iris()\n",
    "X2 = pd.DataFrame(iris2.data)\n",
    "X2.columns = [1,2,3,4]\n",
    "X2[2] = X2[2].sample(frac=0.5,random_state=14)\n",
    "X2[2].describe()\n",
    "iris2.data = X2\n",
    "\n",
    "# so add an imputation step to the pipeline! (5 min, use lecture page!)\n",
    "from sklearn.impute import SimpleImputer\n",
    "knn_pipe2 = make_pipeline(\n",
    "                        SimpleImputer(strategy='mean'), \n",
    "                        preprocessing.StandardScaler(),  # clean the data\n",
    "                        KNeighborsClassifier()           # model\n",
    "                        )\n",
    "cross_validate(knn_pipe2, iris2.data, iris.target, cv=5)['test_score'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary so far:\n",
    "- now we can impute and standardize without code-induced data leakage\n",
    "- your pipeline for the assignment will be more complicated if you want to include categorical vars\n",
    "\n",
    "## optimizing KNN with `GridSearchCV`\n",
    "\n",
    "`GridSearchCV` let's use tweak any parameters from any function in the pipeline\n",
    "\n",
    "Tips:\n",
    "- If any parameters in your grid are optimal at the boundaries, add more points until optimum is interior\n",
    "- After you optimize the model, save it as a model object to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('simpleimputer',\n",
       "                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "                               missing_values=nan, strategy='mean',\n",
       "                               verbose=0)),\n",
       "                ('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('kneighborsclassifier',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search will let you specify all the parameters of the model\n",
    "# you want to tweak, and the values you want to try\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set up parameter grid to try\n",
    "# the parameter grid is a dictionary where key:value pairs are built like:\n",
    "#     stepName<two underlines>paramName : [list of settings to try]\n",
    "\n",
    "param_grid = {'kneighborsclassifier__n_neighbors':[2,5,6,7,8,9,10],   \n",
    "               'standardscaler__with_mean':['True','False'],\n",
    "               'standardscaler__with_std':['True','False']}\n",
    "\n",
    "# like a normal estimator, this has not yet been applied to any data\n",
    "grid = GridSearchCV(knn_pipe2, param_grid=param_grid)\n",
    "grid.fit(iris2.data, iris.target)\n",
    "grid.best_params_\n",
    "\n",
    "# a ha! standardizing (mean=std=True) helps predictions here!\n",
    "\n",
    "# you can see the WHOLE set of attempts by GridSearch using \n",
    "# grid.cv_results_\n",
    "\n",
    "# # now save that pipeline as a model object!\n",
    "optimal_knn_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some post-optimization diagnostics\n",
    "\n",
    "1. print out scores\n",
    "2. graphically explore predictionsd\n",
    "3. in classification problems print out ealrfuhgeporihaeoruh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00598073, 0.00398898, 0.00398707, 0.00398397, 0.0050199 ]),\n",
       " 'score_time': array([0.0039885 , 0.00299406, 0.00299549, 0.00199556, 0.00295806]),\n",
       " 'test_score': array([0.93333333, 0.93333333, 0.96666667, 0.93333333, 1.        ])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print k-fold scoring (like before)\n",
    "cross_validate(optimal_knn_model, iris2.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        27\n",
      "  versicolor       0.89      0.96      0.93        26\n",
      "   virginica       0.95      0.86      0.90        22\n",
      "\n",
      "    accuracy                           0.95        75\n",
      "   macro avg       0.95      0.94      0.94        75\n",
      "weighted avg       0.95      0.95      0.95        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# use classification_report to see which types of Y values \n",
    "# your prediction performs better/worse on\n",
    "###########################################################\n",
    "\n",
    "# to use class_report, we need some predicted y values, so\n",
    "# make a fold and generate predicted values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(iris2.data, iris.target, random_state=9,train_size=.5)\n",
    "y_pred = optimal_knn_model.fit(Xtrain, ytrain).predict(Xtest)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest,\n",
    "                            y_pred,\n",
    "                            target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1af5d0f54c8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# use confusion_matrix see exactly model gets predictions wrong\n",
    "#################################################################\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(optimal_knn_model, Xtest, ytest,   # model and test data\n",
    "                      display_labels=iris.target_names,  # labels\n",
    "                      cmap=plt.cm.Blues,                 # colors\n",
    "                      normalize=None)                    # turns on/off fractions (within row)\n",
    "\n",
    "# note: the normalize parameter is a little weird but changes the outputs \n",
    "# between several useful modes! normalize must be\n",
    "#    = None   (just plots the # in that cell)\n",
    "#    = 'true' (rows add to 100%, meaning: cell # divided by # in that row/true-y outcome)\n",
    "#    = 'pred' (cols add to 100%, meaning: cell # divided by # in that col/predicted-y)\n",
    "#    = 'all'  (cell # divided by sample size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "- We've now seen more post model diagnostics \n",
    "- We can specify the models in `make_pipeline` alongside data cleaning/preprocessing steps that improve model performance without introducing data leakage. \n",
    "- There are many imputation, and scaling methods available in `sklearn`, and which one you use depends on the use-case. (Read about and try several!)\n",
    "- Your pipeline for the assignment will be more complicated if you want to include categorical vars\n",
    "- You can optimize all of the parameters throughout your pipeline using `GridSearchCV`\n",
    "    - `GridSearchCV` also allows you to specify how you create folds\n",
    "    - Which leads us to...\n",
    "\n",
    "**LAST BIG POINT:** \n",
    "- Must of your projects involve an important time series dimension. (Ex: predicting stock returns) \n",
    "- In these cases, `KFold` and `StratifiedKFold` won't work (you can't have 1985 in the test sample)\n",
    "- See: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
