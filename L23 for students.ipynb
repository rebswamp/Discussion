{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting what we have together \n",
    "\n",
    "The broad steps are now quite simple _in principle:_\n",
    "1. Set up the model/pipeline \n",
    "    - **New skill today: dealing with multiple data types in the pipeline using `ColumnTransformer`** <br> <br>\n",
    "    \n",
    "2. Optimize the model's/pipeline's parameters\n",
    "    - E.g. What is the \"best\" strategy for imputing? How should we scale the variables? How many neighbors is the \"best\"? \n",
    "    - Options: `GridSearchCV`, `RandomizedSearchCV`, and SK has some model specific `-CV` functions (e.g. `LassoCV`)\n",
    "    - Tip: print the pipeline to figure out how to specify the parameters keys for  `GridSearchCV` <br> <br>\n",
    "3. Try new combinations of X variables (which to include), X variable transformations (log, non-linear polynomials), and model types (e.g. regression vs logistic), and optimize each \n",
    "    - If you have 40 variables, there are $2^40>billion$ possible combinations. You can't check all of those!    \n",
    "    - Forward selection: \n",
    "        1. Start with empty model and add the variable that generates largest score increase (CV score, AIC, BIC, adj R2)\n",
    "        2. Continue adding variables until some stopping condition is reached \n",
    "    - Backword selection is the opposite. Start with all variables and remove the least helpful. Continue until some stopping condition is reached. Function: `RFECV`.         \n",
    "        - Alternate backwords approaches: `LassoCV` and `SelectFromModel`\n",
    "    - [`sklearn.feature_selection`](https://scikit-learn.org/stable/modules/feature_selection.html) has a bunch of options and examples to show you different approaches for feature selection. Most can be used in a pipeline! :)\n",
    "    \n",
    "    ```python\n",
    "    reg = Pipeline([\n",
    "                      ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))), # or SFM(LassoCV()) \n",
    "                      ('reg', LinearRegression())\n",
    "                    ])\n",
    "    reg.fit(X, y)\n",
    "    ```\n",
    "    <br> <br>\n",
    "4. Compare all the optimized models\n",
    "\n",
    "    ```python\n",
    "    <build list of models>\n",
    "    for model in models:\n",
    "        cross_validate(model, X, y, cv, ...)\n",
    "    ```\n",
    "\n",
    "5. Save the model as an OBJECT others can load and use quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Those 5 steps in pseudo code\n",
    "\n",
    "```python\n",
    "imports \n",
    "load data\n",
    "\n",
    "########################################################################################\n",
    "# STEP 0: EDA\n",
    "########################################################################################\n",
    "\n",
    "Obviously, explore the data and use best practices throughout. This is just pseudo code,\n",
    "not a fully fleshed out \"fill in the blanks\" template\n",
    "\n",
    "########################################################################################\n",
    "# STEP 1: build a pipeline with data cleaning and an estimator\n",
    "########################################################################################\n",
    "\n",
    "# after this, I quickly run pipe_modelName.fit() and pipe_modelName.predict()  \n",
    "# to make sure this works before going forward, but then delete those commands\n",
    "\n",
    "pipe_modelName = make_pipeline(<a sequence of data steps, and the last step is a model>)  \n",
    "\n",
    "########################################################################################\n",
    "# STEP 2: optimize the pipeline\n",
    "########################################################################################\n",
    "\n",
    "# this is the GridSearchCV approach - manually set up the param&value combos to try\n",
    "# doc + examples: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV \n",
    "\n",
    "param_grid = {'stepname__paramname':[val1,val2,...,valN]} # params to try\n",
    "cv = ...                                                  # what folds to use\n",
    "grid = GridSearchCV(pipe_modelName, param_grid,cv,...)    # set up optimizer\n",
    "grid.fit(X,y)                              # fit grid like a \"normal model obj\"\n",
    "optimal_vrs_of_model1 = grid.best_params_  # grid now has new features. save best model\n",
    "\n",
    "# part of this optimization step is picking the best model features\n",
    "\n",
    "########################################################################################\n",
    "# STEP 3: NOW MOVING BEYOND THAT,YOU SHOULD TRY OTHER THINGS! \n",
    "#           (WHAT ARE THE ODDS YOUR FIRST PASS CAN'T BE BEAT?)\n",
    "########################################################################################\n",
    "\n",
    "# MODEL #2\n",
    "# build a new pipeline (e.g. change the model type, which vars to use, how to modify\n",
    "# the vars)\n",
    "# and repeat the pipeline optimization. save the optimal vrs of that model.\n",
    "\n",
    "# MODEL #3\n",
    "# again...\n",
    "\n",
    "...\n",
    "\n",
    "# MODEL #N:\n",
    "# again...\n",
    "\n",
    "########################################################################################\n",
    "# STEP 4: Compare the optimized models\n",
    "########################################################################################\n",
    "\n",
    "# In practice, I'd actually loop through the models with a for-loop and print\n",
    "# the name/scores nicely, but this is just pseudo code\n",
    "\n",
    "cross_validate(optimal_vrs_of_model1,...)   \n",
    "cross_validate(optimal_vrs_of_model2,...) \n",
    "...\n",
    "cross_validate(optimal_vrs_of_modelN,...) \n",
    "\n",
    "########################################################################################\n",
    "# STEP 5: Finishing up\n",
    "########################################################################################\n",
    "\n",
    "# summarize your preferred model (print stats, visual support backing your choice)\n",
    "# save the model as an OBJECT others can load and use quickly\n",
    "\n",
    "we will do this in a minute!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New skill #1: Dealing with multiple variable types\n",
    "\n",
    "### Simple pipelines fail on real world data\n",
    "\n",
    "A pipeline from the last lecture was\n",
    "```python\n",
    "knn_pipe2 = make_pipeline(\n",
    "                        SimpleImputer(strategy='mean'),\n",
    "                        preprocessing.StandardScaler(),  # clean the data\n",
    "                        KNeighborsClassifier()           # model\n",
    "                        )\n",
    "```\n",
    "\n",
    "**The problem is that this won't work if the data has any string (data type = 'object') variables.** Real data usually has \n",
    "- numeric variables that are continuous,\n",
    "- numeric variables that are categorical,\n",
    "- string variables that are categorical,\n",
    "- string variables to process with textual analysis,\n",
    "- variables to ignore. \n",
    "\n",
    "The solution is to build a pipeline that can process different variables differently. Below, I get you set up using the assignment data. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "# DL data\n",
    "url = 'https://github.com/LeDataSciFi/lectures-spr2020/blob/master/assignment_data/Fannie_Mae_Plus_Data.gzip?raw=true'\n",
    "fannie_mae = pd.read_csv(url,compression='gzip') \n",
    "\n",
    "# separate out y var\n",
    "y = fannie_mae['Original_Interest_Rate']\n",
    "fannie_mae.drop('Original_Interest_Rate',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up how each data type will get dealt with\n",
    "\n",
    "Let's start with the continuous numeric variables. Here, I just try a few variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Original_UPB', 'Original_Loan_Term','Original_Debt_to_Income_Ratio']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the categorical features. Again, just a few variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Property_type', 'Loan_purpose']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse=False))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the column-specific transformations with ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.443151</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-0.990988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.101791</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-0.639975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.615504</td>\n",
       "      <td>-1.543334</td>\n",
       "      <td>-0.201208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.121288</td>\n",
       "      <td>-1.543334</td>\n",
       "      <td>-1.429754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.277621</td>\n",
       "      <td>-1.543334</td>\n",
       "      <td>-2.044026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135033</td>\n",
       "      <td>0.101791</td>\n",
       "      <td>-0.814572</td>\n",
       "      <td>1.027337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135034</td>\n",
       "      <td>-0.872994</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>0.500818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135035</td>\n",
       "      <td>0.460438</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-1.166494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135036</td>\n",
       "      <td>-0.882190</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-1.254247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135037</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>0.237558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135038 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2    3    4    5    6    7    8    9   10  \\\n",
       "0      -1.443151  0.642953 -0.990988  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "1       0.101791  0.642953 -0.639975  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "2      -0.615504 -1.543334 -0.201208  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "3      -1.121288 -1.543334 -1.429754  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "4      -1.277621 -1.543334 -2.044026  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "...          ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "135033  0.101791 -0.814572  1.027337  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0   \n",
       "135034 -0.872994  0.642953  0.500818  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "135035  0.460438  0.642953 -1.166494  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "135036 -0.882190  0.642953 -1.254247  0.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "135037 -0.449974  0.642953  0.237558  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n",
       "\n",
       "         11  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "135033  0.0  \n",
       "135034  0.0  \n",
       "135035  0.0  \n",
       "135036  0.0  \n",
       "135037  0.0  \n",
       "\n",
       "[135038 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(fannie_mae)\n",
    "pd.DataFrame(preprocessor.transform(fannie_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is ready to include in a pipeline with an estimator\n",
    "\n",
    "It's as easy as: `make_pipeline(preprocessor, model_of_your_choice())`. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_UPB</th>\n",
       "      <th>Original_Loan_Term</th>\n",
       "      <th>Original_Debt_to_Income_Ratio</th>\n",
       "      <th>Property_type_CO</th>\n",
       "      <th>Property_type_CP</th>\n",
       "      <th>Property_type_MH</th>\n",
       "      <th>Property_type_PU</th>\n",
       "      <th>Property_type_SF</th>\n",
       "      <th>Loan_purpose_C</th>\n",
       "      <th>Loan_purpose_P</th>\n",
       "      <th>Loan_purpose_R</th>\n",
       "      <th>Loan_purpose_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.443151</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-0.990988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.101791</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-0.639975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.615504</td>\n",
       "      <td>-1.543334</td>\n",
       "      <td>-0.201208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.121288</td>\n",
       "      <td>-1.543334</td>\n",
       "      <td>-1.429754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1.277621</td>\n",
       "      <td>-1.543334</td>\n",
       "      <td>-2.044026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135033</td>\n",
       "      <td>0.101791</td>\n",
       "      <td>-0.814572</td>\n",
       "      <td>1.027337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135034</td>\n",
       "      <td>-0.872994</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>0.500818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135035</td>\n",
       "      <td>0.460438</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-1.166494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135036</td>\n",
       "      <td>-0.882190</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>-1.254247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135037</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0.642953</td>\n",
       "      <td>0.237558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135038 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original_UPB  Original_Loan_Term  Original_Debt_to_Income_Ratio  \\\n",
       "0          -1.443151            0.642953                      -0.990988   \n",
       "1           0.101791            0.642953                      -0.639975   \n",
       "2          -0.615504           -1.543334                      -0.201208   \n",
       "3          -1.121288           -1.543334                      -1.429754   \n",
       "4          -1.277621           -1.543334                      -2.044026   \n",
       "...              ...                 ...                            ...   \n",
       "135033      0.101791           -0.814572                       1.027337   \n",
       "135034     -0.872994            0.642953                       0.500818   \n",
       "135035      0.460438            0.642953                      -1.166494   \n",
       "135036     -0.882190            0.642953                      -1.254247   \n",
       "135037     -0.449974            0.642953                       0.237558   \n",
       "\n",
       "        Property_type_CO  Property_type_CP  Property_type_MH  \\\n",
       "0                    0.0               0.0               0.0   \n",
       "1                    0.0               0.0               0.0   \n",
       "2                    0.0               0.0               0.0   \n",
       "3                    0.0               0.0               0.0   \n",
       "4                    0.0               0.0               0.0   \n",
       "...                  ...               ...               ...   \n",
       "135033               0.0               0.0               0.0   \n",
       "135034               0.0               0.0               0.0   \n",
       "135035               0.0               0.0               0.0   \n",
       "135036               0.0               0.0               0.0   \n",
       "135037               0.0               0.0               0.0   \n",
       "\n",
       "        Property_type_PU  Property_type_SF  Loan_purpose_C  Loan_purpose_P  \\\n",
       "0                    0.0               1.0             0.0             1.0   \n",
       "1                    0.0               1.0             0.0             1.0   \n",
       "2                    0.0               1.0             1.0             0.0   \n",
       "3                    0.0               1.0             1.0             0.0   \n",
       "4                    0.0               1.0             1.0             0.0   \n",
       "...                  ...               ...             ...             ...   \n",
       "135033               1.0               0.0             0.0             0.0   \n",
       "135034               0.0               1.0             0.0             0.0   \n",
       "135035               0.0               1.0             0.0             0.0   \n",
       "135036               0.0               1.0             1.0             0.0   \n",
       "135037               0.0               1.0             0.0             1.0   \n",
       "\n",
       "        Loan_purpose_R  Loan_purpose_U  \n",
       "0                  0.0             0.0  \n",
       "1                  0.0             0.0  \n",
       "2                  0.0             0.0  \n",
       "3                  0.0             0.0  \n",
       "4                  0.0             0.0  \n",
       "...                ...             ...  \n",
       "135033             1.0             0.0  \n",
       "135034             1.0             0.0  \n",
       "135035             1.0             0.0  \n",
       "135036             0.0             0.0  \n",
       "135037             0.0             0.0  \n",
       "\n",
       "[135038 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy and paste this, don't go over - they can figure out later\n",
    "# get numerical col names (line 1) + post-transform categorical names (line 2)\n",
    "cols  = preprocessor.transformers_[0][2] .copy()   #t_[0] is num trans,[2] item is col names, copy() so we don't change the underlying data structure!\n",
    "cols += preprocessor.transformers_[1][1]['onehot']\\\n",
    "                     .get_feature_names(cat_features).tolist()  #t_[1] is cat trans,[1] is steps inside cat trans, get onehot, then pull the feature names\n",
    "\n",
    "pd.DataFrame(preprocessor.transform(fannie_mae), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with...\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(categorical_features=None,\n",
       "                                                                                 categories=None,\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 n_values=None,\n",
       "                                                                                 sparse=False))],\n",
       "                                                           verbose=False),\n",
       "                                                  ['Property_type',\n",
       "                                                   'Loan_purpose'])],\n",
       "                                   verbose=False)),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine preprocessor with estimator\n",
    "pipe_reg = make_pipeline(preprocessor,\n",
    "                        LinearRegression())\n",
    "pipe_reg # look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-8-942801a969a2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-942801a969a2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pipe_reg.predict(fannie_mae)'''\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "##could do this\n",
    "pipe_reg.fit(fannie_mae, y)\n",
    "pipe_reg.predict(fannie_mae)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That concludes step 2 in the pseudo, the real-world pipeline is ready!**\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "## Optimizing the overly simply model above\n",
    "\n",
    "Three reasons for doing this: \n",
    "- specifying `param_grid` is just a little different because the pipeline has steps with nested steps\n",
    "- one more example of optimizing a model\n",
    "- you'll see how I'll evaluate your final model\n",
    "\n",
    "Optimizing this pipeline is just like the pseudo code above: set up the parameter grid, then the grid to search, then fit and save the optimized model to an object.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "             'columntransformer__num__imputer__strategy': ['mean', 'median','most_frequent']\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note how we accessed the column transformer, 2 underscores, then the num transformer inside it, 2 underscores,  then the imputer step, then the strategy parameter. I wouldn't have known to do this without looking at the `pipe_reg` output above._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe_reg, param_grid, cv=5,scoring='r2')\n",
    "grid_search.fit(fannie_mae, y)\n",
    "# grid_search.best_params_                   # examined this\n",
    "opt_model_reg = grid_search.best_estimator_  # save best model to an actual model object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_START ASIDE: you can quickly check the model object's R2 in-sample (all of your data) and on the CV folds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does this do insample?\n",
    "print(\"In sample:          \",metrics.r2_score(y,\n",
    "                                              opt_model_reg.predict(fannie_mae)\n",
    "                                             ).round(3)) \n",
    "\n",
    "# lol this model generates negative R2 in the CV folds\n",
    "print(\"Validation fold avg:\",cross_validate(opt_model_reg,\n",
    "                                            fannie_mae, y,\n",
    "                                            scoring=['neg_mean_squared_error','r2']\n",
    "                                           )\n",
    "                                           ['test_r2'].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lol. You probably will want to include more variables.\n",
    "\n",
    "_END ASIDE_\n",
    "\n",
    "---\n",
    "\n",
    "Now, you can drop in the code from [the assignment instructions](https://github.com/LeDataSciFi/LeDataSciFi.github.io/blob/master/assignments/asgn06_pred.md) to save this model to a file I'll evaluate. Make sure to ONLY save your best model!\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - Exercise / Breakout time! \n",
    "\n",
    "Let's break off into groups and try to select which variables to include in a model.\n",
    "\n",
    "Groups can try to implement any of the feature selection at the top of the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# excercise 1: add 5 new continupus variables to your pipeline and see how R2 changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "num_features = ['Original_UPB', 'Original_Loan_Term','Original_Debt_to_Income_Ratio', 'UNRATE', 'rGDP' , 'CPIAUCSL', 'Original_LTV_(OLTV)', 'TCMR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(fannie_mae)\n",
    "pd.DataFrame(preprocessor.transform(fannie_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copy and paste this, don't go over - they can figure out later\n",
    "# get numerical col names (line 1) + post-transform categorical names (line 2)\n",
    "cols  = preprocessor.transformers_[0][2] .copy()   #t_[0] is num trans,[2] item is col names, copy() so we don't change the underlying data structure!\n",
    "cols += preprocessor.transformers_[1][1]['onehot']\\\n",
    "                     .get_feature_names(cat_features).tolist()  #t_[1] is cat trans,[1] is steps inside cat trans, get onehot, then pull the feature names\n",
    "\n",
    "pd.DataFrame(preprocessor.transform(fannie_mae), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_reg = make_pipeline(preprocessor,\n",
    "                        LinearRegression())\n",
    "pipe_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "             'columntransformer__num__imputer__strategy': ['mean', 'median','most_frequent']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipe_reg, param_grid, cv=5,scoring='r2')\n",
    "grid_search.fit(fannie_mae, y)\n",
    "# grid_search.best_params_                   # examined this\n",
    "opt_model_reg = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In sample:          \",metrics.r2_score(y,\n",
    "                                              opt_model_reg.predict(fannie_mae)\n",
    "                                             ).round(3)) \n",
    "\n",
    "# lol this model generates negative R2 in the CV folds\n",
    "print(\"Validation fold avg:\",cross_validate(opt_model_reg,\n",
    "                                            fannie_mae, y,\n",
    "                                            scoring=['neg_mean_squared_error','r2']\n",
    "                                           )\n",
    "                                           ['test_r2'].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example 2: add 2 new categorical variabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Property_type', 'Loan_purpose', 'Occupancy_type', 'Mortgage_Insurance_type', 'Loan_indentifier']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_reg = make_pipeline(preprocessor,\n",
    "                        LinearRegression())\n",
    "pipe_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "             'columntransformer__num__imputer__strategy': ['mean', 'median','most_frequent']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In sample:          \",metrics.r2_score(y,\n",
    "                                              opt_model_reg.predict(fannie_mae)\n",
    "                                             ).round(3)) \n",
    "\n",
    "# lol this model generates negative R2 in the CV folds\n",
    "print(\"Validation fold avg:\",cross_validate(opt_model_reg,\n",
    "                                            fannie_mae, y,\n",
    "                                            scoring=['neg_mean_squared_error','r2']\n",
    "                                           )\n",
    "                                           ['test_r2'].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find variables to ignore, that do not effectr R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['Loan_indentifier', 'Qdate', 'Origination_date']\n",
    "dumb_nums = fannie_mae.select_dtypes('number').columns.to_list()\n",
    "dumb_cats = [ele for ele in fannie_mae.columns if ele not in dumb_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ##add vars\n",
    "cat_features = ##add vars\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)])\n",
    "pipe_reg = make_pipeline(preprocessor,\n",
    "                        LinearRegression() ##add selectfrommodel\n",
    "                        )\n",
    "pipe_reg\n",
    "print(\"In sample:          \",metrics.r2_score(y,\n",
    "                                              opt_model_reg.predict(fannie_mae)\n",
    "                                             ).round(3)) \n",
    "\n",
    "# lol this model generates negative R2 in the CV folds\n",
    "print(\"Validation fold avg:\",cross_validate(opt_model_reg,\n",
    "                                            fannie_mae, y,\n",
    "                                            scoring=['neg_mean_squared_error','r2']\n",
    "                                           )\n",
    "                                           ['test_r2'].mean().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LabelBinarizer' from 'sklearn.preprocessing' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fdf249cea4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# add a selection preprocessing step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m pipe_reg = make_pipeline(preprocessor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LabelBinarizer' from 'sklearn.preprocessing' (unknown location)"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# add a selection preprocessing step\n",
    "pipe_reg = make_pipeline(preprocessor,\n",
    "                        SelectFromModel(LassoCV()),     # turn this on/off to see diff                    \n",
    "                        LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
